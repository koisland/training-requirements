{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33facea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr, shapiro, ttest_ind, boxcox, linregress\n",
    "import plotly.express as px\n",
    "from IPython.display import HTML, IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd62e35",
   "metadata": {},
   "source": [
    "#### 1) Read in the `gapminder_clean.csv` data as a `pandas` `DataFrame`.\n",
    "\n",
    "``` python\n",
    "df = pd.read_csv(\"gapminder_clean.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e356dba",
   "metadata": {},
   "source": [
    "#### 2) Filter the data to include only rows where `Year` is `1962` and then make a scatter plot comparing `'CO2 emissions (metric tons per capita)'` and `gdpPercap for the filtered data.`\n",
    "\n",
    "``` python\n",
    "filt_df = df[df[\"Year\"] == 1962]\n",
    "co2_gdp_splt = sns.scatterplot(data = filt_df, x= \"CO2 emissions (metric tons per capita)\", y = \"gdpPercap\")\n",
    "```\n",
    "\n",
    "![Test](files/CO2_emissions_(metric_tons_per_capita)_vs._gdpPercap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d881e3a",
   "metadata": {},
   "source": [
    "#### Preprocess by removing empty rows.\n",
    "```python\n",
    "# Remove rows if one or other has nas.\n",
    "nas = filt_df[\"gdpPercap\"].isna() | filt_df[\"CO2 emissions (metric tons per capita)\"].isna()\n",
    "filt_df = filt_df[~nas]\n",
    "\n",
    "# Check that length of obs in each col is equal.\n",
    "assert(len(filt_df[\"CO2 emissions (metric tons per capita)\"]) == len(filt_df[\"gdpPercap\"]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618027c1",
   "metadata": {},
   "source": [
    "#### 3) On the filtered data, calculate the pearson correlation of `CO2 emissions (metric tons per capita)` and `gdpPercap`. What is the Pearson R value and associated p value?\n",
    "\n",
    "```python\n",
    "# By-hand\n",
    "# https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/\n",
    "covariance = np.cov(filt_df[\"CO2 emissions (metric tons per capita)\"], filt_df[\"gdpPercap\"])\n",
    "```\n",
    "The second row and first column is the covariance between `CO2 emissions (metric tons per capita)` and `gdpPercap`.\n",
    "\n",
    "```python\n",
    "array([[2.46358644e+01, 4.48639240e+04],\n",
    "       [4.48639240e+04, 9.52638497e+07]])\n",
    "```\n",
    "\n",
    "```python\n",
    "p_corr_coeff = covariance[1,0] / (np.std(filt_df[\"CO2 emissions (metric tons per capita)\"]) * np.std(filt_df[\"gdpPercap\"]))\n",
    "```\n",
    "\n",
    "The pearson correlation between `'CO2 emissions (metric tons per capita)'` and `gdpPercap` can also be found using `scipy.stats`'s `pearsonr` function.\n",
    "\n",
    "```python\n",
    "# Using scipy.stats.pearsonr\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "r, prob = pearsonr(filt_df[\"CO2 emissions (metric tons per capita)\"], filt_df[\"gdpPercap\"])\n",
    "```\n",
    "\n",
    "**The correlation coefficient (`r`) is ~0.926 with a probability (`prob`) of 1.129e-46.**\n",
    "* This implies that there is a strong correlation between CO2 emissions per cap and gross domestic product per cap with a low probability of producing this r by random chance from uncorrelated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518455f",
   "metadata": {},
   "source": [
    "#### 4) On the unfiltered data, answer \"In what year is the correlation between `'CO2 emissions (metric tons per capita)'` and `gdpPercap` the strongest?\" Filter the dataset to that year for the next step...\n",
    "\n",
    "```python\n",
    "years = df[\"Year\"].unique()\n",
    "\n",
    "# create functions to repeat data processing and stat calculations\n",
    "def remove_nas(df, col1, col2):\n",
    "    nas = df[col1].isna() | df[col2].isna()\n",
    "    filt_df = df[~nas]\n",
    "    return filt_df\n",
    "\n",
    "def filter_df_year(df, year):\n",
    "    filt_df = df[df[\"Year\"] == year]\n",
    "    # remove rows if one or other has nas\n",
    "    filt_df = remove_nas(filt_df, \"CO2 emissions (metric tons per capita)\", \"gdpPercap\")\n",
    "    return filt_df\n",
    "\n",
    "def yearly_correlation(df, year):\n",
    "    filt_df = filter_df_year(df, year)\n",
    "    r, prob = pearsonr(filt_df[\"CO2 emissions (metric tons per capita)\"], filt_df[\"gdpPercap\"])\n",
    "    return r, prob\n",
    "\n",
    "r_for_year = [yearly_correlation(df, year)[0] for year in years]\n",
    "\n",
    "highest_r_year = years[list(r_for_year).index(max(r_for_year))]\n",
    "\n",
    "```\n",
    "\n",
    "**The correlation between `CO2 emissions (metric tons per capita)` and `gdpPercap` is strongest in `1967`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2be7f",
   "metadata": {},
   "source": [
    "#### 5) Using plotly or bokeh, create an interactive scatter plot comparing `'CO2 emissions (metric tons per capita)'` and `gdpPercap`, where the point size is determined by `pop` (population) and the color is determined by the `continent`.\n",
    "\n",
    "```python\n",
    "df_h_r = filter_df_year(df, highest_r_year)\n",
    "\n",
    "fig = px.scatter(df_h_r, \n",
    "                 x = df_h_r[\"CO2 emissions (metric tons per capita)\"], y = df_h_r[\"gdpPercap\"], \n",
    "                 size = df_h_r[\"pop\"], color = df_h_r[\"continent\"], \n",
    "                 title = \"CO2 emissions (metric tons per capita) vs. gfpPercap\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19be6c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mIFrame\u001b[49m(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco2_em_gfppcap.html\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IFrame' is not defined"
     ]
    }
   ],
   "source": [
    "IFrame(src='co2_em_gfppcap.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe51364",
   "metadata": {},
   "source": [
    "#### 1. What is the relationship between `continent` and `'Energy use (kg of oil equivalent per capita)'`?\n",
    "\n",
    "Here, a correlation coefficient between `continent` and `Energy use (kg of oil equivalent per capita)` was calculated.\n",
    "\n",
    "First, any na values were removed from the dataset and `continent` was convertedto categorical codes.\n",
    "```python\n",
    "df_cnt_energy = remove_nas(df, \"continent\", \"Energy use (kg of oil equivalent per capita)\")\n",
    "\n",
    "# convert continent column to categorical nums for tests\n",
    "df_cnt_energy[\"continent\"] = df_cnt_energy[\"continent\"].astype(\"category\").cat.codes\n",
    "```\n",
    "\n",
    "Next, normality of both columns was calculated using the Shapiro-Wilk test.\n",
    "```python\n",
    "# https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n",
    "# shapiro-wilk test checks for normality of sample data, H0 is that drawn from norm dist.\n",
    "norm_test_cnt = shapiro(df_cnt_energy[\"continent\"])\n",
    "norm_test_energy = shapiro(df_cnt_energy[\"Energy use (kg of oil equivalent per capita)\"])\n",
    "\n",
    "cols_norm = True\n",
    "alpha = 0.05\n",
    "if norm_test_energy.pvalue > alpha and norm_test_cnt.pvalue > alpha:\n",
    "    print(\"Fail to reject H0 for both columns. Both are normal.\")\n",
    "else:\n",
    "    cols_norm = False\n",
    "    print(\"Rejected H0 for a column. One column and/or other not normal.\")\n",
    "```\n",
    "\n",
    "`cols_norm` outputs `False` and both of the columns have p-values below `alpha` (0.05); this means that the H0 can be rejected and that the data from the columns is normally distributed.\n",
    "\n",
    "Knowing this, the Spearman's correlation (a non-parametric test) can be used to check if the two columns are correlated.\n",
    "\n",
    "```python\n",
    "if cols_norm:\n",
    "    r, prob = pearsonr(df_cnt_energy[\"continent\"], df_cnt_energy[\"Energy use (kg of oil equivalent per capita)\"])\n",
    "else:\n",
    "    r, prob = spearmanr(df_cnt_energy[\"continent\"], df_cnt_energy[\"Energy use (kg of oil equivalent per capita)\"])\n",
    "\n",
    "```\n",
    "\n",
    "The Spearman's correlation coefficient (`r`) is `0.573` (`p = 3.289e-75`); **this suggests a positive, slightly high correlation between `continent` and `Energy use (kg of oul equivalent per capita`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb76a3",
   "metadata": {},
   "source": [
    "#### 2) Is there a significant difference between Europe and Asia with respect to `Imports of goods and services (% of GDP)` in the years after 1990? (Stats test needed)\n",
    "\n",
    "To check if there is a significant difference between Europe and Asia in `Imports of goods and services (% of GDP)` after the 1990s, a t-test (Student's or Welch's) was used for two samples.\n",
    "\n",
    "First, the dataset was filtered taking only observations where the `Year` is greater than 1990. \n",
    "\n",
    "```python\n",
    "df_post90s = df[df[\"Year\"] > 1990]\n",
    "```\n",
    "\n",
    "Next, the dataset is cleaned of `na`s, filtered, and separated into two new dataframes: one where `continent` is Asia and the other where it is Europe.\n",
    "\n",
    "```python\n",
    "imp_col = \"Imports of goods and services (% of GDP)\"\n",
    "df_post90s = remove_nas(df_post90s, \"continent\", imp_col)\n",
    "\n",
    "df_post90s_asia = df_post90s[df_post90s[\"continent\"] == \"Asia\"]\n",
    "df_post90s_europe = df_post90s[df_post90s[\"continent\"] == \"Europe\"]\n",
    "```\n",
    "\n",
    "Calculating the standard deviation (stdev) of both sample columns determines whether the Student's T-test or Welch's T-test should be used.\n",
    "* If the **stdev of one column is double** that of the other, the **Welch's T-test** is used *(McDonald 130)*.\n",
    "    * The Student's T-test assumes equal variance.\n",
    "* **Otherwise, the Student's T-test** is used.\n",
    "\n",
    "In this case, the standard deviation of `Imports of goods and services (% of GFP)` the filtered Asia dataset was twice (~2.003) that of the Europe dataset. With unequal variance, the Welch's T-test was used.\n",
    "```python\n",
    "p90s_asia_imp_std = np.std(df_post90s_asia[imp_col])\n",
    "p90s_eur_imp_std = np.std(df_post90s_europe[imp_col])\n",
    "\n",
    "# If stdev of one sample is two times larger than the other, then use Welch's t-test instead of Student's t-test\n",
    "std_ratio = p90s_asia_imp_std / p90s_eur_imp_std\n",
    "\n",
    "imp_cols = df_post90s_asia[imp_col], df_post90s_europe[imp_col]\n",
    "\n",
    "if std_ratio < 2 or std_ratio > 0.5:\n",
    "    # equal_var arg uses welch's t-test\n",
    "    print(\"Using Welch's T-test.\")\n",
    "    t_stat, t_p = ttest_ind(*imp_cols, equal_var=False)\n",
    "else:\n",
    "    print(\"Using Student's T-test.\")\n",
    "    t_stat, t_p = ttest_ind(*imp_cols)\n",
    "```\n",
    "\n",
    "The resulting test **statistic was 1.355** and the **p-value was 0.178**. \n",
    "* As the p-value was above `alpha` of 0.05, the **H0 cannot be rejected and there is no significant difference between the means.** \n",
    "\n",
    "#### Works Cited\n",
    "1. *McDonald, John H., Handbook of Biological Statistics, Sparky House Publishing, 2014*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bddfa",
   "metadata": {},
   "source": [
    "#### 3) What is the country (or countries) that has the highest `Population density (people per sq. km of land area)` across all years? (i.e., which country has the highest average ranking in this category across each time point in the dataset?)\n",
    "\n",
    "In this dataset, the years are 1967,1972, 1977, 1982, 1987, 1992, 1997, 2002, and 2007\n",
    "```python\n",
    "years = df[\"Year\"].unique()\n",
    "```\n",
    "\n",
    "Group the dataset by `Year` and use the `agg` method to find the maximum index of `Population density (people per sq. km of land area)`.\n",
    "```python\n",
    "res = df.groupby([\"Year\"]).agg({f\"{pop_den_col}\":\"idxmax\"})\n",
    "```\n",
    "\n",
    "Then, access the dataset indices output from `res` and take the `Year` and `Country Name`.\n",
    "\n",
    "```python\n",
    "df.loc[res[pop_den_col]].loc[:, [\"Year\", \"Country Name\"]]\n",
    "```\n",
    "\n",
    "This yields the following years and associated countries.\n",
    "```python\n",
    "{1962: 'Monaco', 1967: 'Monaco', 1972: 'Macao SAR, China', 1977: 'Monaco', 1982: 'Monaco', 1987: 'Macao SAR, China', 1992: 'Macao SAR, China', 1997: 'Macao SAR, China', 2002: 'Macao SAR, China', 2007: 'Monaco'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ebf478",
   "metadata": {},
   "source": [
    "#### 4) What country (or countries) has shown the greatest increase in `Life expectancy at birth, total (years)` since 1962?\n",
    "\n",
    "First, filter the dataset to `Year`s greater than 1962.\n",
    "```python\n",
    "df_post1962 = df[df[\"Year\"] > 1962]\n",
    "```\n",
    "\n",
    "Group `df_post1962` by `Country Name` and apply `scipy.stats` linear regress function, `linregress` to the dataset using the columns `Year` and `Life expectancy at birth, total (years)`. \n",
    "\n",
    "```python\n",
    "dle_dt = df_post1962.groupby(\"Country Name\").apply(lambda x: linregress(x[\"Year\"], x[life_exp_col]).slope)\n",
    "```\n",
    "\n",
    "Taking the slope attribute from the `linregress` object shows us how `Life expectancy at birth, total (years)` changes over `Year` since 1962.\n",
    "\n",
    "```python\n",
    "... linregress(x[\"Year\"], x[life_exp_col]).slope\n",
    "```\n",
    "\n",
    "To check the country and its slope...\n",
    "```python\n",
    "dle_dt.idxmax(), dle_dt.loc[dle_dt.idxmax()]\n",
    "```\n",
    "\n",
    "\n",
    "**The country with the largest positive slope is Maldives with a slope of ~0.850; this means that the average life expectancy has increased by 0.850 years per year from 1967 to 2007.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
